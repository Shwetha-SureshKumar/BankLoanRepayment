{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.8"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2 id=\"understanding_data\">Here are what the columns represent:</h2>\nLoan_ID               object\n\nGender                object\n\nMarried               object\n\nDependents            object\n\nEducation             object\n\nSelf_Employed         object\n\nApplicantIncome        int64\n\nCoapplicantIncome    float64\n\nLoanAmount           float64\n\nLoan_Amount_Term     float64\n\nCredit_History       float64\n\nProperty_Area         object\n\nLoan_Status           object","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf=pd.read_csv(\"BankLoanRepayment.csv\")\nprint(\"DataFrame  shape : \",df.shape)","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"DataFrame  shape :  (614, 13)\n","output_type":"stream"}]},{"cell_type":"code","source":"#To -do : 1) GetDummies 2) LabelEncoder","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"Categorical_Columns=df.select_dtypes(include='object').columns.tolist()\nCategorical_Columns.remove('Loan_ID')\nprint(Categorical_Columns)\nNumeric_Columns=df.select_dtypes(exclude='object').columns.tolist()\nprint(Numeric_Columns)","metadata":{"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status']\n['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term', 'Credit_History']\n","output_type":"stream"}]},{"cell_type":"code","source":"for n in Categorical_Columns:\n    df[n].replace(np.NaN,'NA',inplace=True)\nfor n in Numeric_Columns:\n    df[n].replace(np.NaN,0,inplace=True)","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\"\"\"df[Categorical_Columns].replace(np.NaN,0,inplace=True)\ndf['CoapplicantIncome'].replace(np.NaN,0,inplace=True)\ndf['LoanAmount'].replace(np.NaN,0,inplace=True)\ndf['Loan_Amount_Term'].replace(np.NaN,0,inplace=True)\ndf['Credit_History'].replace(np.NaN,0,inplace=True)\ndf['Gender'].replace(np.NaN,'Undefined',inplace=True)\ndf['Married'].replace(np.NaN,'Undefined',inplace=True)\ndf['Dependents'].replace(np.NaN,'0',inplace=True)\ndf['Education'].replace(np.NaN,'Not Specified',inplace=True)\ndf['Self_Employed'].replace(np.NaN,'NA',inplace=True)\"\"\"","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"\"df[Categorical_Columns].replace(np.NaN,0,inplace=True)\\ndf['CoapplicantIncome'].replace(np.NaN,0,inplace=True)\\ndf['LoanAmount'].replace(np.NaN,0,inplace=True)\\ndf['Loan_Amount_Term'].replace(np.NaN,0,inplace=True)\\ndf['Credit_History'].replace(np.NaN,0,inplace=True)\\ndf['Gender'].replace(np.NaN,'Undefined',inplace=True)\\ndf['Married'].replace(np.NaN,'Undefined',inplace=True)\\ndf['Dependents'].replace(np.NaN,'0',inplace=True)\\ndf['Education'].replace(np.NaN,'Not Specified',inplace=True)\\ndf['Self_Employed'].replace(np.NaN,'NA',inplace=True)\""},"metadata":{}}]},{"cell_type":"code","source":"X=df[['Gender','Married','Dependents','Education','Self_Employed','ApplicantIncome','CoapplicantIncome','LoanAmount',\n      'Loan_Amount_Term','Credit_History','Property_Area']].values\ny=df[['Loan_Status']].values","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nimport numpy as np\n\nGender_Unique=np.unique(X[:,0]).tolist()\nif('NA' in Gender_Unique):\n    Gender_Unique.remove('NA')\n    Gender_Unique.insert(0,'NA')\nMarried_Unique=np.unique(X[:,1]).tolist()\nif('NA' in Married_Unique):\n    Married_Unique.remove('NA')\n    Married_Unique.insert(0,'NA')\nDependents_Unique=np.unique(X[:,2]).tolist()\nif('NA' in Dependents_Unique):\n    Dependents_Unique.remove('NA')\n    Dependents_Unique.insert(0,'NA')\nEducation_Unique=np.unique(X[:,3]).tolist()\nSelf_Employed_Unique=np.unique(X[:,4]).tolist()\nif('NA' in Self_Employed_Unique):\n    Self_Employed_Unique.remove('NA')\n    Self_Employed_Unique.insert(0,'NA')\nProperty_Area_Unique=np.unique(X[:,10]).tolist()\nif('NA' in Property_Area_Unique):\n    Property_Area_Unique.remove('NA')\n    Property_Area_Unique.insert(0,'NA')","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Pre-Processing\nfrom sklearn import preprocessing\nimport numpy as np\nEncoder=preprocessing.LabelEncoder()\nX[:,0]=Encoder.fit(Gender_Unique).transform(X[:,0])\nX[:,1]=Encoder.fit(Married_Unique).transform(X[:,1])\nX[:,2]=Encoder.fit(Dependents_Unique).transform(X[:,2])\nX[:,3]=Encoder.fit(Education_Unique).transform(X[:,3])\nX[:,4]=Encoder.fit(Self_Employed_Unique).transform(X[:,4])\nX[:,10]=Encoder.fit(Property_Area_Unique).transform(X[:,10])\n\n\"\"\"X[:,1]=preprocessing.LabelEncoder().fit(Married_Unique).transform(X[:,1])\nX[:,3]=preprocessing.LabelEncoder().fit(Dependents_Unique).transform(X[:,3])\nX[:,4]=preprocessing.LabelEncoder().fit(Education_Unique).transform(X[:,4])\nX[:,10]=preprocessing.LabelEncoder().fit(Property_Area_Unique).transform(X[:,10])\"\"\"\n\"\"\"\nMarried=preprocessing.LabelEncoder().fit(np.unique(np.array(X[:,1]).delete('Undefined').append('Undefined')))\nX[:,1]=Married.transform(X[:,1])\n\nEducation=preprocessing.LabelEncoder().fit(np.unique(np.array(X[:,3]).delete('Not Specified').append('Not Specified')))\nX[:,3]=Education.transform(X[:,3])\n\nSelf_Employed=preprocessing.LabelEncoder().fit(np.unique(np.array(X[:,4]).delete('NA').append('NA')))\nX[:,4]=Self_Employed.transform(X[:,4])\n\nProperty_Area=preprocessing.LabelEncoder().fit(np.unique(np.array(X[:,10]).delete('Undefined').append('Undefined')))\nX[:,10]=Property_Area.transform(X[:,10])\"\"\"","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"\"\\nMarried=preprocessing.LabelEncoder().fit(np.unique(np.array(X[:,1]).delete('Undefined').append('Undefined')))\\nX[:,1]=Married.transform(X[:,1])\\n\\nEducation=preprocessing.LabelEncoder().fit(np.unique(np.array(X[:,3]).delete('Not Specified').append('Not Specified')))\\nX[:,3]=Education.transform(X[:,3])\\n\\nSelf_Employed=preprocessing.LabelEncoder().fit(np.unique(np.array(X[:,4]).delete('NA').append('NA')))\\nX[:,4]=Self_Employed.transform(X[:,4])\\n\\nProperty_Area=preprocessing.LabelEncoder().fit(np.unique(np.array(X[:,10]).delete('Undefined').append('Undefined')))\\nX[:,10]=Property_Area.transform(X[:,10])\""},"metadata":{}}]},{"cell_type":"code","source":"\"\"\"X=df[['int.rate','installment','dti']].values\ny=df[['not.fully.paid']].values\"\"\"\n\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=4)\n#print('X_train :',X_train[0:5])\n#print('y_train :',y_train[0:5])\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 1\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh\nyhat = neigh.predict(X_test)\nprint(X_test[0:5])\nprint(y_test[0:5])\nprint(yhat[0:5])","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[[1 1 0 0 1 2526 1783.0 145.0 360.0 1.0 0]\n [1 2 1 0 1 3315 0.0 96.0 360.0 1.0 1]\n [0 2 0 0 1 4583 0.0 112.0 360.0 1.0 0]\n [1 1 0 0 1 3418 0.0 127.0 360.0 1.0 1]\n [1 2 1 0 1 9538 0.0 187.0 360.0 1.0 2]]\n[['Y']\n ['Y']\n ['N']\n ['N']\n ['Y']]\n['Y' 'Y' 'N' 'N' 'Y']\n","output_type":"stream"},{"name":"stderr","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  del sys.path[0]\n/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/neighbors/base.py:908: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  self._y = np.empty(y.shape, dtype=np.int)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat),'\\n')\n\nfrom sklearn.metrics import jaccard_score\nprint('Train Jaccard Score is : ',jaccard_score(y_train,neigh.predict(X_train),pos_label='Y'))\nprint('Test Jaccard Score is : ',jaccard_score(y_test,yhat,pos_label='Y'),'\\n')\n\nfrom sklearn.metrics import f1_score\nprint('Train F1_Score Score is : ',f1_score(y_train,neigh.predict(X_train),pos_label='Y'))\nprint('Test F1_Score Score is : ',f1_score(y_test,yhat,pos_label='Y'),'\\n')\n\nfrom sklearn.metrics import log_loss\nprint('Train Log_loss Score is : ',log_loss(list(map(lambda x:int(str(x).replace(\"['Y']\",'1').replace(\"['N']\",'0')), y_train.tolist())),\n                    list(map(lambda x:int(x.replace('Y','1').replace('N','0')), neigh.predict(X_train).tolist()))))\nprint('Test Log_loss Score is : ',log_loss(list(map(lambda x:int(str(x).replace(\"['Y']\",'1').replace(\"['N']\",'0')), y_test.tolist())),list(map(lambda x:int(x.replace('Y','1').replace('N','0')), yhat.tolist()))))","metadata":{"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Train set Accuracy:  1.0\nTest set Accuracy:  0.5853658536585366 \n\nTrain Jaccard Score is :  1.0\nTest Jaccard Score is :  0.5363636363636364 \n\nTrain F1_Score Score is :  1.0\nTest F1_Score Score is :  0.6982248520710059 \n\nTrain Log_loss Score is :  9.992007221626413e-16\nTest Log_loss Score is :  14.321131587569594\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndrugTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 10)\ndrugTree # it shows the default parameters\ndrugTree.fit(X_train,y_train)\npredTree = drugTree.predict(X_test)\nprint(predTree [0:5])\nprint(list(map(lambda x:str(x).replace('[','').replace(']',''),y_test[0:5].tolist())))","metadata":{"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"['Y' 'Y' 'Y' 'Y' 'Y']\n[\"'Y'\", \"'Y'\", \"'N'\", \"'N'\", \"'Y'\"]\n","output_type":"stream"},{"name":"stderr","text":"/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/tree/tree.py:163: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  y_encoded = np.zeros(y.shape, dtype=np.int)\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, predTree),'\\n')\n\nfrom sklearn.metrics import jaccard_score\nprint('Train Jaccard Score is : ',jaccard_score(y_train,neigh.predict(X_train),pos_label='Y'))\nprint('Test Jaccard Score is : ',jaccard_score(y_test,predTree,pos_label='Y'),'\\n')\n\nfrom sklearn.metrics import f1_score\nprint('Train F1_Score Score is : ',f1_score(y_train,neigh.predict(X_train),pos_label='Y'))\nprint('Test F1_Score Score is : ',f1_score(y_test,predTree,pos_label='Y'),'\\n')\n\nfrom sklearn.metrics import log_loss\nprint('Train Log_loss Score is : ',log_loss(list(map(lambda x:int(str(x).replace(\"['Y']\",'1').replace(\"['N']\",'0')), y_train.tolist())),\n                    list(map(lambda x:int(x.replace('Y','1').replace('N','0')), neigh.predict(X_train).tolist()))))\nprint('Test Log_loss Score is : ',log_loss(list(map(lambda x:int(str(x).replace(\"['Y']\",'1').replace(\"['N']\",'0')), y_test.tolist())),list(map(lambda x:int(x.replace('Y','1').replace('N','0')), predTree.tolist()))))","metadata":{"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Train set Accuracy:  1.0\nTest set Accuracy:  0.6504065040650406 \n\nTrain Jaccard Score is :  1.0\nTest Jaccard Score is :  0.6018518518518519 \n\nTrain F1_Score Score is :  1.0\nTest F1_Score Score is :  0.7514450867052022 \n\nTrain Log_loss Score is :  9.992007221626413e-16\nTest Log_loss Score is :  12.074694105015563\n","output_type":"stream"}]}]}